#!/usr/bin/env python

from selenium import webdriver
import time
import smtplib
import datetime
import collections

"""
Collects weekly info on equity funds. Uses Selenium as a scraper instead of other alternatives because the content needed is generated by client-side javascript.
"""

def init_webdriver():

    #Starts the webdriver.

    global driver
    driver = webdriver.Firefox()


def exit_webdriver():

    #Closes the webdriver.

    driver.close()
    driver.quit()


def scrape_specific_fund(fund_list):

    #Collects info on specific fund(s). fund_list needs to be a list with strings that match the last part of the url from avanza.se, for example: "3101/carnegie-indienfond". Returns a dictionary.

    spec_funds = collections.OrderedDict()

    for fund in fund_list:

        url = "https://www.avanza.se/fonder/om-fonden.html/" + fund
        driver.get(url)

        time.sleep(5)

        fund_element = driver.find_element_by_xpath("/html/body/div[1]/div/div/div/div[2]/div/div/div[3]/div[1]/div[1]/div[1]/div[1]/div")
        weekly_element = driver.find_element_by_xpath("/html/body/div[1]/div/div/div/div[2]/div/div/div[3]/div[1]/div[4]/div/div[2]/table/tbody/tr[2]/td[2]")

        spec_funds.update({fund_element.text:weekly_element.text})

    return spec_funds


def scrape_toplist():

    #Gathers info from Nordnet on the top 10 performing equity funds from the last week. Returns a dictionary with the results.

    toplist_funds = collections.OrderedDict()

    url = "https://www.nordnet.se/mux/web/fonder/topplistorMeny.html?topplista=100&kategori=100&nm=aktiefond,+1+vecka"

    driver.get(url)
    time.sleep(5)

    for n in range(10):
        fund_element = driver.find_element_by_xpath("/html/body/div[2]/div[2]/div[2]/div/table/tbody/tr[{}]/td[2]/div/a".format(str(n+1)))
        kurs_element = driver.find_element_by_xpath("/html/body/div[2]/div[2]/div[2]/div/table/tbody/tr[{}]/td[6]/span".format(str(n+1)))

        toplist_funds.update({fund_element.text:kurs_element.text})

    return toplist_funds


def send_email(toplist, specific):

    #This function sends the collected info to my gmail inbox.

    #This first part generates content strings from the dictionaries.

    top_content = ""
    specific_content = ""

    for k,v in toplist.items():
        top_content += k + " - " + v
        top_content += "% \n"

    for k,v in specific.items():
        specific_content += k + " - " + v
        specific_content += "% \n"


    #And here is where the actual mail sending happens. I use my localhost smtp-server.

    sender = 'root@solsjenitsyn'
    receivers  = ['o.serrander@gmail.com']

    msg = '''From: {} \nTo: {} \nSubject: Weekly fund update - {} \nTop 10 funds this week: \n\n{}\nSpecific fund(s) of interest: \n\n{}'''

    msg = msg.format(sender, receivers[0], str(datetime.date.today()), top_content, specific_content)

    server = smtplib.SMTP('localhost:25')
    server.ehlo('localhost')
    server.starttls()
    server.mail(sender)
    server.rcpt(receivers[0])
    server.data(msg)
    server.quit()


if __name__ == '__main__':

    #Example usage.

    init_webdriver()

    fund_list = ["3101/carnegie-indienfond"]

    spec = scrape_specific_fund(fund_list)
    top = scrape_toplist()

    send_email(top,spec)

    exit_webdriver()

